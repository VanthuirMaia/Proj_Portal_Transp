# PROJ_PORTAL_TRANSP

**Projeto pr√°tico de Engenharia de Dados com dados p√∫blicos reais**

---

## üìå Vis√£o Geral

Este projeto foi criado com o objetivo de **aprender Engenharia de Dados de forma pr√°tica**, utilizando **dados reais do Portal da Transpar√™ncia do Governo Federal**, enfrentando problemas reais de qualidade, padroniza√ß√£o, volume e integra√ß√£o.

O foco n√£o √© apenas consumir dados, mas **construir um pipeline completo**, bem estruturado, version√°vel e evolutivo, seguindo boas pr√°ticas utilizadas em ambientes profissionais.

> Aprendizado baseado em **projeto**, n√£o em exemplos artificiais.

---

## üéØ Objetivos do Projeto

- Consumir APIs p√∫blicas reais com autentica√ß√£o e pagina√ß√£o
- Implementar camadas de dados (**RAW ‚Üí STAGING ‚Üí ANALYTICS**)
- Tratar dados inconsistentes e sem contrato
- Aplicar regras de **qualidade de dados**
- Evoluir para modelagem dimensional
- Utilizar **dbt** para transforma√ß√£o, testes e documenta√ß√£o
- Preparar o pipeline para orquestra√ß√£o com **Airflow**
- Consolidar o projeto como **case t√©cnico de portf√≥lio**

---

## üóÇÔ∏è Estrutura de Pastas

```
PROJ_PORTAL_TRANSP/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/            # Dados brutos extra√≠dos da API (CSV com timestamp)
‚îÇ   ‚îú‚îÄ‚îÄ staging/        # Dados tratados e tipados (Parquet)
‚îÇ   ‚îú‚îÄ‚îÄ warehouse/      # Banco DuckDB com dados carregados
‚îÇ   ‚îî‚îÄ‚îÄ analytics/      # Dados prontos para an√°lise (Gold Layer)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/      # Scripts de ingest√£o (API ‚Üí RAW)
‚îÇ   ‚îú‚îÄ‚îÄ transformation/ # Scripts de transforma√ß√£o (RAW ‚Üí STAGING)
‚îÇ   ‚îú‚îÄ‚îÄ quality/        # Regras e valida√ß√µes de qualidade de dados
‚îÇ   ‚îî‚îÄ‚îÄ utils/          # Fun√ß√µes utilit√°rias
‚îÇ
‚îú‚îÄ‚îÄ scripts/            # Scripts DuckDB (queries, views, carga)
‚îú‚îÄ‚îÄ dbt/                # Projeto dbt (modelagem, testes, docs)
‚îú‚îÄ‚îÄ airflow/            # Orquestra√ß√£o (planejado)
‚îú‚îÄ‚îÄ notebooks/          # An√°lises explorat√≥rias e valida√ß√µes
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.exemplo
‚îî‚îÄ‚îÄ README.md
```

---

## üîå Fonte de Dados

**Portal da Transpar√™ncia ‚Äì Governo Federal**

### Endpoint inicial (dimens√£o)

```
GET /api-de-dados/orgaos-siafi
```

### Endpoint principal (fato)

```
GET /api-de-dados/despesas/por-orgao
```

Os dados utilizados s√£o os mesmos disponibilizados publicamente no portal, acessados via API REST.

---

## ‚öôÔ∏è Tecnologias Utilizadas

- Python 3.12
- Pandas
- Requests
- PyArrow (Parquet)
- DuckDB (warehouse anal√≠tico)
- dotenv
- dbt (pr√≥xima etapa)
- Airflow (planejado)

---

## üß≠ Roteiro do Projeto (checkpoint)

| Etapa | Descri√ß√£o | Status |
|-------|-----------|--------|
| 1 | Escolher fonte de dados (API p√∫blica) | ‚úÖ Conclu√≠do |
| 2 | Ingest√£o Python: consumir API e salvar CSV | ‚úÖ Conclu√≠do |
| 3 | Camada staging: CSV ‚Üí Parquet | ‚úÖ Conclu√≠do |
| 4 | Regras de qualidade de dados | ‚úÖ Conclu√≠do |
| 5 | Warehouse DuckDB: inicializar e carregar staging | ‚úÖ Conclu√≠do |
| 6 | Queries anal√≠ticas SQL (agrega√ß√µes, rankings) | ‚úÖ Conclu√≠do |
| 7 | Views anal√≠ticas no DuckDB | ‚úÖ Conclu√≠do |
| 8 | Projeto dbt com testes e documenta√ß√£o | üî≤ Pendente |
| 9 | Visualiza√ß√£o (Power BI / Metabase) | üî≤ Pendente |
| 10 | Orquestra√ß√£o com Airflow | üî≤ Pendente |

---

## ‚úÖ O que j√° foi implementado

### Infraestrutura
- Estrutura de pastas organizada e versionada
- Configura√ß√£o segura de vari√°veis de ambiente (`.env.exemplo`)

### Ingest√£o (`src/ingestion/`)
- Consumo paginado de APIs p√∫blicas
- Scripts: `fetch_orgaos_siafi.py`, `fetch_despesas_por_orgao.py`
- Camada **RAW** com versionamento por timestamp

### Transforma√ß√£o (`src/transformation/`)
- Tipagem expl√≠cita e normaliza√ß√£o de valores monet√°rios
- Convers√£o CSV ‚Üí Parquet
- Sa√≠da em `data/staging/`

### Qualidade (`src/quality/`)
- Valida√ß√£o de valores n√£o negativos
- Coer√™ncia financeira: `empenhado ‚â• liquidado ‚â• pago`
- Unicidade l√≥gica por `(ano, codigo_orgao)`

### Warehouse DuckDB (`scripts/`)
- Banco inicializado em `data/warehouse/portal_transparencia.duckdb`
- Staging carregado no DuckDB
- Queries anal√≠ticas: totais e rankings por √≥rg√£o
- View anal√≠tica `vw_ranking_orgaos` criada

---

## üìä Dataset Atual (STAGING)

Tabela: `stg_despesas_por_orgao`

| Campo                 | Tipo      |
| --------------------- | --------- |
| ano                   | int       |
| codigo_orgao          | string    |
| orgao                 | string    |
| codigo_orgao_superior | string    |
| orgao_superior        | string    |
| valor_empenhado       | float     |
| valor_liquidado       | float     |
| valor_pago            | float     |
| carga_timestamp       | timestamp |

---

## üß™ Qualidade de Dados

Regras implementadas:

- Valores monet√°rios n√£o negativos
- Coer√™ncia financeira entre empenhado, liquidado e pago
- Unicidade l√≥gica por `(ano, codigo_orgao)`

Essas regras servem como base para contratos de dados e testes futuros no dbt.

---

## üöÄ Pr√≥ximos Passos

### Fase 1 ‚Äî dbt (pr√≥ximo)

- [ ] Criar projeto dbt em `dbt/` com adapter DuckDB
- [ ] Configurar `profiles.yml` apontando para o warehouse
- [ ] Modelar staging (`stg_despesas_por_orgao`) no dbt
- [ ] Criar marts/dimens√µes (ex: `dim_orgaos`, `fct_despesas`)
- [ ] Implementar testes declarativos (`unique`, `not_null`, `relationships`)
- [ ] Gerar documenta√ß√£o autom√°tica (`dbt docs generate`)

### Fase 2 ‚Äî Visualiza√ß√£o

- [ ] Conectar Power BI ou Metabase ao DuckDB
- [ ] Criar dashboard com m√©tricas de despesas
- [ ] Explorar s√©ries temporais e comparativos

### Fase 3 ‚Äî Automa√ß√£o

- [ ] Criar DAG no Airflow para orquestrar o pipeline
- [ ] Implementar alertas e retry em caso de falha
- [ ] Documentar o projeto como case de portf√≥lio

---

## üìå Filosofia do Projeto

Este projeto segue uma abordagem **realista**:

- Dados reais s√£o imperfeitos
- APIs falham
- Ambientes quebram
- Qualidade precisa ser expl√≠cita
- Engenharia vem antes de dashboards

> O objetivo n√£o √© apenas fazer funcionar,  
> √© **entender, justificar e sustentar cada decis√£o t√©cnica**.

---

## ‚úçÔ∏è Autor

Projeto desenvolvido para estudo e aprofundamento em **Engenharia de Dados**, com foco em aprendizado cont√≠nuo baseado em projetos reais.
